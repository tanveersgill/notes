- perhaps have a network object, initialized with the sizes of the layers
- make the network start off with random weights and biases, storing the results in a vector
	- i think its best to use Normal/Gaussian distribution, luckily c++ stl has that:
	~~~
	std::normal_distribution
	~~~
	- how many?
		- each neuron needs to have as many weights as it has inputs, and one bias.
			- so like, the hidden layer neurons will have as many weights as there neurons in the previous layer, since each neuron from the previous layer will be contributing a number to the current
	- additionally, the weights should be stored in a list of matrices
		- with this setup, weights represent the strength of a connection between a neuron in one layer and another at the previous layer
		- for instance, `the third weight of a neuron in the current layer indicates the strength of its connection to the third neuron in the previous layer`
		$$\displaylines{
		w=\begin{bmatrix}
		w_{0,0}\ \cdot\ \cdot\ \cdot\ w_{0,n}
		\\
		\cdot\cdot\cdot\
		\\
		w_{m,0}\ \cdot\cdot\ \cdot\ w_{m,n}
		\end{bmatrix}
		\\represents\ a\ layer!
		\\
		and\ we\ use\ a\ list\ of\ these,\ one\ entry\ per\ layer.
		}$$
		- each row represents a neuron in that layer.
		- given an input of activations for any layer, we have produce an output for that layer:
		$$
		\displaylines{
		(wa+b)\\ gives\ a\ vector\ of\ the\ weighted\ sums\ for\ the\ layer
		\\\\
		the\ output\ of\ the\ layer\ is\ the\ sigmoid\ function\ applied\ to\ each\ entry:
		\\
		a'= \sigma(wa+b)
		}
		$$
		in C++, I'll probably be looking at a `vector<vector<vector<float>>>` for this
- have a function that loops over the layers, applying the previous function to each 'input', and feeding it forward to the next layer. it should finally return the last output once the loop ends

***implementing stochastic gradient descent***
- function will take in:
1. list of `std::pair`'s, representing trainin inputs and their desired outputs
2. mini batch size (the size of a single mini batch)
3. epoch (the number of mini batches to train with)
4. eta (Î· / learning rate)

- so, for every mini batch, one step of gradient descent is applied with backpropagation
	- i.e. 