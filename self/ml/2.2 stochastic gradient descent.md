~~~
in the previous notes, i wrote about gradient descent with weights and biases
however, this 'plain' approach can end up being very computationally demanding, as i'll explain here:

but also, keep in mind we don't really care about the ACTUAL gradient, more so that we move in a general direction that will minimize it.
~~~
- so, we've been talking about the "gradient of the cost function", and minimizing it this whole time.
	- thats a bit of a simplification; in practice, we don't actually compute a single gradient for just one cost function. rather, the 'overall' gradient across all training examples is an average.
	- it might help to figure out how exactly we got the following cost function, which incorporates all costs:
	$$
	\displaylines{
C(\vec{w},b)=\frac{1}{2n}\sum_{x}||\ y(x)-a\ ||^{2}}
	$$
$$\displaylines{
1. \ for\ a\ single\ input,\ we\ have\ the\ mean\ squared\ error:\\||\ y(x)-a\ ||^{2}\\ [note]:here\ we\ divide\ by\ 2\ to\ simplify\ the\ math\ when\ deriving\ later\ on;\ it\ does\ not\ impact\ the\ result. \\ \frac{||\ y(x)-a\ ||^{2}}{2}\\\\
2. \ then,\ we\ took\ an\ average\ across\ all\ n\ costs,\ (for\ all\ inputs):\\ \frac{1}{n}\sum_{n} ||\ y(x)-a\ ||^{2} \\\\
3. \ the\ problem: \ we\ can't\ use\ this\ 'average\ cost'\ in\ gradient\ descent
}
$$
***makes you wonder, so how do we actually get the gradient we've been working with this whole time?***
- well, **∇C** is actually the average of *all* the gradients for *all* the training inputs:

$$
\nabla C = \frac{1}{n} \sum_{x}\nabla C_{x}
$$
- in practice, what this means is having to compute the gradient for every single input...
	- for a huge number of training inputs, this would take a long time.

# enter stochastic gradient descent
- the idea is to, instead of calculating the gradient for every single training input, take a random sample of inputs, called a mini batch, with each input denoted with X
	- then, we can use those to ***estimate*** **∇C**
	- we say:
$$
\displaylines{
pick\ out\ m\ gradients.\ then,\\
\nabla C \approx \frac{1}{m} \sum_{i=0}^{m}\nabla C_{i}
\\
"\ the\ gradient\ is\ roughly\ the\ average\ of\ m\ random\ gradients\ "
}
$$
- taking "steps" to find new weights and biases:
  $$
  \displaylines{
  w_{k}\ ' = w_{k}-\eta \frac{1}{m}\sum_{j}\frac{\partial C_{X_{j}}}{\partial w_{k}}
  \\and\\
  b_{l}\ ' = b_{l}-\eta \frac{1}{m}\sum_{j}\frac{\partial C_{X_{j}}}{\partial b_{l}}
  }
  $$
  - ^ here, notice to "take a step", we don't use a gradient vector. instead, we average the weight and bias components of that vector (the partial derivatives)
  - basically, what the above equations are saying is:
	  - find the average direction of steepest descent across the chosen mini batch of inputs for both the weights and biases, and then take a small step in those directions. so the direction that minimizes C with respect to the weights, then the direction that minimizes C with respect to biases.
- then, after going through the mini batch, we can pick out another (random) mini batch