***feedforward neural networks***
- neural networks in which the output of one layer is user as an input for the next layer, as we've seen thus far

***cost/loss functions***
- we refer to x as an input vector containing n digits representing all n pixels of the input
- then, the expected output is y, or y(x), which is a 10-dimensional vector containing the desired output for a particular x
- 'a' is the actual output vector for an input vector x
~~~
basically, a cost function quantifies the difference between an actual output, compared to the expected output

in a way, it tells us how badly the model is performing
~~~

$$
\displaylines{
mean\ square\ error:\\
C(\vec{w},b)=\frac{1}{2n}\sum_{x}||\ y(x)-a\ ||^{2}}
$$

***gradient descent for learning***
- gradient descent is an algorithm used to minimize the cost function!!!!
	- usually the cost function in question is mean absolute error or mean square error
~~~
at a basic level, learning goes something like this:
1. have a cost function. its parameters are all of the weights and biases in the network.
2. figure out the gradient for said cost function
3. since the gradient gives the direction of steepest ascent, take the negative of that is the direction of steepest descent
	1. take a tiny step in that direction.
	2. repeat step 3 to find the new direction of steepest descent from your new position, until reaching a minimum
~~~

"***okay, but how do we actually do the minimizing?***"
- **first**, remember that the gradient of the cost function is the vector of its partial derivatives:
$$
\nabla C = \begin{bmatrix}\ \frac{\partial C}{\partial v_{1}} \\ \frac{\partial C}{\partial v_{2}}\\...\end{bmatrix},
where\ v\ is\ the\ function's\ parameters
$$
	- additionally, gradients give the direction of steepest ascent. thus, the direction of steepest descent is negative that.
	
-  **second**, remember the total differential. 
	- here, it lets us see how the cost function changes with changes to the variables the function depends upon
		$$
		\Delta C = \frac{\partial C}{\partial v_{1}}\Delta v_{1}\ +\ ...
	   $$
- putting it together, if we put the changes in the variables into a vector, we can condense this into a dot product:
	$$
	\displaylines
	{\Delta C = \nabla C\ \cdot \Delta v,
	\\ where\ \Delta v=\begin{bmatrix}
	\Delta v_{1}
	\\
	\Delta v_{2}
	\\
	...
	\end{bmatrix},\ a\ vector\ with\ the\ changes\ in\ parameters
	}
	$$

~~~
^ using the above, we can play around with the vector v to see which values make ùö´C negative!
~~~
- this is where ***learning rate*** (Œ∑) comes in
	- it's basically the "step size" for the algorithm when it tries to move in a certain direction

- **third**, we'll pick ùö´v to be a vector that takes a small step in the direction of steepest descent:
$$
\displaylines{
\Delta v = \textcolor{red}{-}\ \textcolor{orange}{\eta}\ \textcolor{yellow}{\nabla C}
\\\\
-\nabla C\ denotes\ the\ direction\ of\ steepest\ descent
\\
and
\\ 
\eta\ is\ a\ small\ +ve\ scalar\ representing\ our\ 'step'}
$$
- putting what we have thus far together, we can rewrite ùö´C (the change in cost):
$$
\Delta C \approx -\eta\ ||\nabla C||^{2}
$$
- **lastly,** we just have to update the current position and repeat as we navigate to a minimum of the cost function:
~~~
the 'new' position is the 'old' position, with a step taken in the direction of steepest descent. in mathematical terms:
~~~
$$
v'=v-\eta\ \nabla C
$$
- this is cool since v is a vector of all of the parameters we care to optimize, and the gradient is in terms of all of those parameters